//Adam2
1. Carrier specific changes in workbench, db
2. Database update
3. Info and error logging
4. Error handling test

Process
1. Get first 5 digits of tracking no. That is account no. Get user name, password as per following logic
2. Get token by calling http get request with header. Token will be available in Token header of response. Body will have "authorized". https://api.gso.com/Rest/v1/token, Headers will be: AccountNumber,UserName, Password
3. Tracking info url is: https://api.gso.com/Rest/v1/TrackShipment?TrackingNumber=508741111116172&AccountNumber=50874. Two headers: 1) Token 2) Content-Type: application/json




UPS
If AccountNo = "50308" Then
            gsotrackrequest.AccountNumber = AccountNo
            userinfo.UserName = "Wineshipping"
            userinfo.Password = "WS50308"
        ElseIf AccountNo = "50874" Then
            gsotrackrequest.AccountNumber = AccountNo
            userinfo.UserName = "VintageLogistics"
            userinfo.Password = "VL50874"
        ElseIf AccountNo = "60278" Then
            gsotrackrequest.AccountNumber = AccountNo
            userinfo.UserName = "Wineshipping"
            userinfo.Password = "WS60278"
        ElseIf AccountNo = "11111" Then
            gsotrackrequest.AccountNumber = "50874"
            userinfo.UserName = "VintageLogistics"
            userinfo.Password = "VL50874"
        End If


https://api.gso.com/Rest/v1/token





//adam2
1. Create test database
2. Get Big object
3. Create 4 object arrays one for each carrier
4. Provide settings.json file for app wide settings
5. Config.js for global configurations and global variables
6. For each carrier set logic for get, get with header, post request call
7. Provide settings for all carriers in settings.json file
8. In parallel do api calls for all 4 carriers.
9. Use piston for queue control. Piston setting for each carrier is in settings.json.
10. At return from each carrier get return object which may be XML. Convert this XML to unified JSON object. 
    Push this unified JSON object to queue. Use a separate node.js module for XML to json conversion.
11. Process objects from queue. Create set of sql's which update info table, add in history and inserts in log table. Use 
    multiple connection channels.
12. At end of each api call and database call mark the job as ended and log to database.
13. Full node.js error handling
14. Complete logs may be using azure telemetry
15. Clean up memory
16. Provide domain level and module level error handling

//Saby
0.1 Send me script for creating 50,000 rows info table, so that I can create the table.
1. Deploy to azure the complete solution and test
2. As per our meeting with Viraj, do complete the solution, deploy and test in Azure using Telemetry for logging